{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Object Tracking x Object Detection"
      ],
      "metadata": {
        "id": "tZuikR-5X7Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Tracking Algorithms** use probabilities to predict the position of the object in the next frame. That makes more efitience from detect faces with oclusion.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=300 src=\"https://nanonets.com/blog/content/images/2019/07/messi_football_track.gif\">\n",
        "</p>\n",
        "\n",
        "The **Detection Algorithms** execute from scratch frame by frame.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=300 src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg/220px-Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "adCOxujGYHAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwBjWLvyGLV5",
        "outputId": "ca2e5423-2f5f-4acb-8ef3-350c615959a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "videos_path = \"/content/drive/MyDrive/Colab Notebooks/Computer_Vision/Object_Tracking/videos/\"\n",
        "videos      = [f\"{videos_path}{file}\" for file in os.listdir(videos_path)]"
      ],
      "metadata": {
        "id": "L5OCswy9MCoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8NTZYVKNMno",
        "outputId": "10c1a265-0934-4cae-dcba-024a15dc116d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/Computer_Vision/Object_Tracking/videos/street.mp4',\n",
              " '/content/drive/MyDrive/Colab Notebooks/Computer_Vision/Object_Tracking/videos/race.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KCF (Kernel Correlation Filters)"
      ],
      "metadata": {
        "id": "ApBNzb_GbTmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://images.deepai.org/converted-papers/1801.06729/x2.png\">\n",
        "</p>\n",
        "\n",
        "- **Initialization** Frame **1**\n",
        "  \n",
        "  Initialize the [ red ] **bounding box**. From this bounding box are generated 2 more bounding boxes, with the same center just changing the scale\n",
        "\n",
        "- **Translation** Estimation Frame **2** and Frame **3**\n",
        "\n",
        "  Update the most external [ green ] bounding box\n",
        "\n",
        "- **Translation** Estimation Frame **4** and Frame **5**\n",
        "\n",
        "  Update the middle [ blue ] bounding box\n",
        "\n",
        "- **Scale** Estimation Frame n + 1 = **6**\n",
        "\n",
        "  Update the most internal [ red ] bounding box\n",
        "\n",
        "- **Translation** Estimation Frame n + 2 = **7**\n",
        "\n",
        "  Update the most external [ green ] bounding box\n",
        "\n",
        "  The purpose is decrease the [ green ] bounding box\n",
        "\n",
        "This 3 bounding boxes are used when we have a sudden change. If the person in the above image move the face and stay inside of the [ green ] bounding box, the algorithm will stay tracking the face.\n",
        "\n",
        "This algorithm is fast but, considering the above explanation, not good for videos with fast movements.\n"
      ],
      "metadata": {
        "id": "XDSmWnkobZX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracker = cv.TrackerKCF_create()"
      ],
      "metadata": {
        "id": "ac3KzB8U_tXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv.VideoCapture(videos[0])"
      ],
      "metadata": {
        "id": "aMTyk2hcGXBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok, frame = video.read()"
      ],
      "metadata": {
        "id": "qBiOP6hjGan2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open a window to select a region of interest"
      ],
      "metadata": {
        "id": "p5dc2CosyWqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bbox = cv.selectROI(frame)"
      ],
      "metadata": {
        "id": "X9HExlASNj0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok = tracker.init(frame, bbox)"
      ],
      "metadata": {
        "id": "Evr3kbWQ_b84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  ok, frame = video.read()\n",
        "\n",
        "  if not ok:\n",
        "      break\n",
        "\n",
        "  ok, bbox = tracker.update(frame)\n",
        "\n",
        "  if ok:\n",
        "    (x, y, w, h) = [int(value) for value in bbox]\n",
        "\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2, 1)\n",
        "\n",
        "  else:\n",
        "    cv2.putText(frame, \"Error\", (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "  cv2.imshow(\"Tracking\", frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == 27: # ESC\n",
        "      break"
      ],
      "metadata": {
        "id": "hxxwauGb_gC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSRT (Discriminative Correlation Filter with Channel and Spatial Reliability)"
      ],
      "metadata": {
        "id": "irDW_fabbZpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img width=800 src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcStbO74AeaKVqnjRlskFyVL8VW2P3ebjsiUlw&usqp=CAU\">\n",
        "<p>\n",
        "\n",
        "- **Trainig Patch/Region**\n",
        "\n",
        "  The selection of object to tracking\n",
        "\n",
        "- **Spatial Prior**\n",
        "\n",
        "  We use the HOG (Histogram of Oriented Gradients) technique to extract useful informations from image\n",
        "\n",
        "- **Backprojection**\n",
        "\n",
        "  Image areas that have some kind of movement\n",
        "\n",
        "  Apply Random Markov Test to generate probabilities of the others places to the movement \n",
        "\n",
        "- **Posterior**\n",
        "\n",
        "  Inicates the area where we will possibly have a movement\n",
        "\n",
        "- **Overlayed Patch/Region**\n",
        "\n",
        "  The mask generated\n",
        "\n",
        "Is slower than KCF but have higher quality"
      ],
      "metadata": {
        "id": "oskIfuUKbkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracker = cv.TrackerCSRT_create()"
      ],
      "metadata": {
        "id": "MX_nzsRL_mP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv.VideoCapture(videos[0])"
      ],
      "metadata": {
        "id": "iTM5JHKS_mQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok, frame = video.read()"
      ],
      "metadata": {
        "id": "sciTxKNM_mQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open a window to select a region of interest"
      ],
      "metadata": {
        "id": "ri14KZyz_mQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bbox = cv.selectROI(frame)"
      ],
      "metadata": {
        "id": "sGrJMZe3_mQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok = tracker.init(frame, bbox)"
      ],
      "metadata": {
        "id": "XnvPBv0l_mQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  ok, frame = video.read()\n",
        "\n",
        "  if not ok:\n",
        "      break\n",
        "\n",
        "  ok, bbox = tracker.update(frame)\n",
        "\n",
        "  if ok:\n",
        "    (x, y, w, h) = [int(value) for value in bbox]\n",
        "\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2, 1)\n",
        "\n",
        "  else:\n",
        "    cv2.putText(frame, \"Error\", (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "  cv2.imshow(\"Tracking\", frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == 27: # ESC\n",
        "      break"
      ],
      "metadata": {
        "id": "eMSHpUJX_mQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencies"
      ],
      "metadata": {
        "id": "AS-sqKNaoTJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.python.org/\n",
        "\n",
        "https://opencv.org/\n",
        "\n",
        "https://www.udemy.com/share/105kta3@ooAfVkatgqpSKV1VF16mPNNje_G4hKtgyPgGU8RyXnIOwR4LhxSq-Ky4SgHKJdHuLA==/\n",
        "\n",
        "https://nanonets.com/blog/object-tracking-deepsort/\n",
        "\n",
        "https://arxiv.org/pdf/1611.08461.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "lSU0-zduoVL9"
      }
    }
  ]
}